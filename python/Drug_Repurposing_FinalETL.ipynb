{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# FDA Drug Repurposing - Join and Load to CAS\n",
    "\n",
    "0) run this AFTER DrugBank & FDA Clinical Trials python processes\n",
    "\n",
    "1) set up envrionment\n",
    "- if download directories match Box - this program should run without modification\n",
    "- to enable CAS table load:\n",
    "    - edit Cell 3 \"casenabled\" to true\n",
    "    - modify CAS server to your address\n",
    "    - modify CAS ID to your ID\n",
    "    - and add your password\n",
    "\n",
    "2) Read in dimensions for drug repositioning\n",
    "<br><br>\n",
    "- DrugBank: Drug (pre processed by DrugBank_drug_target_relationship_v2.ipynb)\n",
    "dbSmallM_df = pd.read_csv(DBPath + 'DrugBank_CSVs/drugbank-slim.tsv', sep='\\t')\n",
    "dbIndication_df = pd.read_csv(DBPath + 'DrugBank_CSVs/drugbank-indication.tsv', sep='\\t')\n",
    "- DrugBank: Drug/Protein\n",
    "dbProteins_df = pd.read_csv(DBPath + 'DrugBank_CSVs/proteins.tsv', sep='\\t')\n",
    "- DrugBank: synonyms\n",
    "fObj = open(DBPath+'DrugBank_CSVs/aliases.json',)\n",
    "\n",
    "<br><br>\n",
    "- ClinicalTrials: COVID Truth (pre processed by FDA_Read_ClinicalTrialsTruth.ipynb)\n",
    "Truth_df = pd.read_csv(CTPath + 'ProposedTruth.csv')\n",
    "truthFinal_df = pd.read_csv(CASPublicPath + 'truthfinal.csv') - from PUBLIC CASLIB\n",
    "\n",
    "<br><br>\n",
    "- UniProt: Protein synonym IDs for joining Drugbank, String and VirusHost proteins<br>\n",
    "with open(UniProtPath + 'HUMAN_9606_idmapping.dat') as f:\n",
    "    row_count = sum(1 for row in f)\n",
    "display(row_count)\n",
    "\n",
    "    source: https://ftp.uniprot.org/pub/databases/uniprot/current_release/knowledgebase/idmapping/by_organism/\n",
    "<br><br>\n",
    "- VirusHost: SARS Related Virus to Host Protein\n",
    "    - VirusHostProt_df = pd.read_csv(VHProtPath + 'HCoV-associated host proteins.csv')\n",
    "- String: Protein-Protein\n",
    "    - stringPP_df = pd.read_csv(STRINGPath + '9606.protein.links.v11.0.txt', sep=' ')\n",
    "<br>\n",
    "\n",
    "3) write out base tables to CASLIB + CSVs\n",
    "- UniProt Lookups\n",
    "    - UniProtGeneIDs_df.to_csv(CSVOut+\"/\"+\"UniProtGeneIDs.csv\")\n",
    "    - UniProtGeneIDs_ct = s.upload_file(data=UniProtGeneIDs_df, casout=dict(name='UniProtGeneIDs', caslib='public', replication=0, promote=True))\n",
    "    \n",
    "    - UniProtSTRINGIDs_df.to_csv(CSVOut+\"/\"+\"UniProtSTRINGIDs.csv\")\n",
    "    - UniProtSTRINGIDs_ct = s.upload_file(data=UniProtSTRINGIDs_df, casout=dict(name='UniProtSTRINGIDs', caslib='public', replication=0, promote=True))\n",
    "    \n",
    "    - UniProtGeneNames_df.to_csv(CSVOut+\"/\"+\"UniProtGeneNames.csv\")\n",
    "    - UniProtGeneNames_ct = s.upload_file(data=UniProtGeneNames_df, casout=dict(name='UniProtGeneNames', caslib='public', replication=0, promote=True))\n",
    "\n",
    "- Truth Sources\n",
    "    - Truth_df.to_csv(CSVOut+\"/\"+\"Truth.csv\")\n",
    "    - Truth_ct = s.upload_file(data=Truth_df, casout=dict(name='Truth', caslib='public', replication=0, promote=True, label=\"Clinical Trials Truth: NOTE needs to be refined\"))\n",
    "\n",
    "    - truthMatch2_df.to_csv(CSVOut+\"/\"+\"newTruth.csv\")\n",
    "    - newTruth_ct = s.upload_file(data=truthMatch2_df, casout=dict(name='newTruth', caslib='public', replication=0, promote=True, label=\"Clinical Trials Truth: NOTE needs to be refined\"))\n",
    "\n",
    "- String mapped to UniProt so it will match DrugBank Drug-Protein IDs\n",
    "    - stringPP_ct = s.upload_file(data=stringPP_df, casout=dict(name='stringPP', caslib='public', replication=0, promote=True, label=\"STRING Protein Protein interactions NOTE Missing UniProt Matches\"))\n",
    "    - stringPP_df.to_csv(CSVOut+\"/\"+\"stringPP.csv\")\n",
    "\n",
    "- Virus Host Protein mapped to UniProt so it will match DrugBank Drug-Protein IDs\n",
    "    - VirusHostProt_df.to_csv(CSVOut+\"/\"+\"VirusHostProt.csv\")\n",
    "    - VirusHostProt_ct = s.upload_file(data=VirusHostProt_df, casout=dict(name='VirusHostProt', caslib='public', replication=0, promote=True, label=\"Virus Host Protein Relationships NOTE: Many Proteins had 1+ UniProt IDs\"))\n",
    "\n",
    "- DrugBank_IDs mapped to both \"truth\" tables\n",
    "    - x.to_csv(CSVOut+\"/\"+\"dbSmallM_Truth.csv\")\n",
    "    - dbSmallM_ct = s.upload_file(data=x, casout=dict(name='dbSmallM_Truth', caslib='public', replication=0, promote=True, label=\"Drug Bank: Small Molecule drugs (NOTE additional attributes available plus stings need to be parsed)\"))\n",
    "\n",
    "- Drugbank Drug-Proteins\n",
    "    - dbProteins_df.to_csv(CSVOut+\"/\"+\"dbProteins.csv\")\n",
    "    - dbProteins_ct = s.upload_file(data=dbProteins_df, casout=dict(name='dbProteins', caslib='public', replication=0, promote=True, label=\"Drug Bank: Small Molcule related proteins (NOTE not all captured by XML parser yet)\"))\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1) setup environment"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# load packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import time\n",
    "import getpass\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# files / paths\n",
    "print(os.getcwd())\n",
    "FDAPath = os.getcwd() + '/../data/source/'\n",
    "\n",
    "CTPath = FDAPath + 'ClinicalTrials/'\n",
    "DBPath = FDAPath + \"DrugBank/\"\n",
    "STRINGPath = FDAPath + 'STRING/'\n",
    "VHProtPath = FDAPath + 'VirusHostProteins/'\n",
    "UniProtPath = FDAPath + 'UniProt/'\n",
    "\n",
    "# CASPublicPath = '/opt/sas/viya/config/data/cas/default/public/'   # truthfinal.csv exported from cas\n",
    "CSVOut = FDAPath + '../DrugRepositioning'\n",
    "\n",
    "print(os.getcwd())\n",
    "os.chdir(FDAPath)\n",
    "print(os.getcwd())\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# link to CAS\n",
    "# https://developer.sas.com/guides/python-swat.html\n",
    "\n",
    "casenabled = False\n",
    "casServerURL = \"pdcesx06019.exnet.sas.com\"\n",
    "\n",
    "casPort = 5570\n",
    "sasid = 'sasdemo'\n",
    "saspw = 'xxxxx'\n",
    "if casenabled == True:\n",
    "    saspw = '<set your pw here>' #getpass.getpass() \n",
    "    import swat\n",
    "    s = swat.CAS(casServerURL, casPort, sasid, saspw)\n",
    "    #s = swat.CAS(\"pdcesx15065.exnet.sas.com\", 5570, 'sasdemo', authinfo='/home/sasdemo/.authinfo')\n",
    "    print(\"CAS is enabled\")\n",
    "else:\n",
    "    print(\"No CAS\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "if casenabled == True:\n",
    "    s.serverstatus()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2) read base tables"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# DrugBank (this is a database with multiple tables)\n",
    "#  pre-processed in drug_target_relationship_DrugBank_rkc.ipynb\n",
    "#  note: needs more work (as of 2021 02 18)\n",
    "\n",
    "# drug bank - same info as \"Slim\" but all IDs instead of just small molecule\n",
    "#db_df = pd.read_csv(DBPath + 'drugbank.tsv', sep='\\t')\n",
    "#display(db_df.head())\n",
    "\n",
    "# drug bank - Small Molecule IDs only\n",
    "dbSmallM_df = pd.read_csv(DBPath + 'DrugBank_CSVs/drugbank-slim.tsv', sep='\\t')\n",
    "dbIndication_df = pd.read_csv(DBPath + 'DrugBank_CSVs/drugbank-indication.tsv', sep='\\t')\n",
    "display(dbSmallM_df.shape)\n",
    "dbSmallM_df = dbSmallM_df.merge(dbIndication_df[['drugbank_id', 'indication']], on='drugbank_id', how='left')\n",
    "display(dbSmallM_df.shape)\n",
    "display(dbSmallM_df.head())\n",
    "del dbIndication_df\n",
    "\n",
    "dbProteins_df = pd.read_csv(DBPath + 'DrugBank_CSVs/proteins.tsv', sep='\\t')\n",
    "dbProteins_df = dbProteins_df.merge(dbSmallM_df[['drugbank_id']], on='drugbank_id', how='inner')\n",
    "display(dbProteins_df.shape)\n",
    "display(dbProteins_df.head())\n"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# FDA Truth - list of DrugBank Drug IDs that should be considered the \"right\" answers\n",
    "#  pre-processed in FDA_Read_ClinicalTrialsTruth.ipynb\n",
    "#  note: needs more work (as of 2021 02 18)\n",
    "Truth_df = pd.read_csv(CTPath + 'ProposedTruth.csv')\n",
    "display(Truth_df.head())\n",
    "\n",
    "Truth_df.rename(columns = {'iDBID':'drugbank_id'}, inplace = True)\n",
    "Truth_df['truth'] = 1\n",
    "Truth_df = Truth_df[['drugbank_id', 'truth', 'iDBIDCount', 'iName', 'inputRowCount', 'inputRowIDs']]\n",
    "display(Truth_df.shape)\n",
    "display(Truth_df.head())\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Truth Final - from (?) inn CAS Public folder\n",
    "# probably could read directly from PUBLIC caslib\n",
    "\n",
    "#####  NOTE !!!   This came AFTER the above table - was imported to CAS \n",
    "#####               a new source was appended\n",
    "#####               and now this replaces the above in the process\n",
    "\n",
    "truthFinal_df = pd.read_csv(CTPath + 'truthfinal.csv')\n",
    "display(truthFinal_df.shape)\n",
    "display(truthFinal_df.head(20))\n"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# match CASLIB truthFinal to Drugbank synonyms json\n",
    "# (extracted code from FDA_Read_ClincalTrialsTruth.ipynb)\n",
    "\n",
    "\n",
    "import json\n",
    "\n",
    "fObj = open(DBPath+'DrugBank_CSVs/aliases.json',)\n",
    "DBAlias = json.load(fObj)\n",
    "fObj.close()\n",
    "\n",
    "print(DBAlias.__class__)\n",
    "display(DBAlias['DB12466'])\n",
    "display(DBAlias[\"DB15327\"])\n",
    "\n",
    "# search dict in DBAlias format to return ID if element of an array matches\n",
    "def searchDBAlias(byVal):\n",
    "    keysList = []\n",
    "    itemsList = DBAlias.items()\n",
    "    for item in itemsList:\n",
    "        if byVal in item[1]:\n",
    "            keysList.append(item[0])\n",
    "    return keysList\n",
    "\n",
    "# this could be sped up if it becomes an issue\n",
    "start = time.time()\n",
    "truthFinal_df['Trail_Drug_DBID'] = truthFinal_df['Trail_Drug'].apply(searchDBAlias)\n",
    "lapse = time.time() - start \n",
    "print(\"lapse time to match: \", lapse)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# count Drug Bank ID matches\n",
    "truthFinal_df['iDBIDCount'] = truthFinal_df['Trail_Drug_DBID'].astype('str').str.count(\"'\")/2 \n",
    "display(truthFinal_df.shape)\n",
    "display(truthFinal_df.head(20))\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "display(truthFinal_df.shape)\n",
    "display(truthFinal_df.head(20))\n",
    "\n",
    "#display(truthFinal_df.Trail_Drug_DBID.apply(len)==0)\n",
    "#display(truthFinal_df.NewDrug==1)\n",
    "#display(np.logical_and(truthFinal_df.NewDrug==1, truthFinal_df.Trail_Drug_DBID.apply(len)==0))\n",
    "\n",
    "#display(truthFinal_df[np.logical_and((truthFinal_df.NewDrug==0), (truthFinal_df.Trail_Drug_DBID.apply(len)!=0))].shape)\n",
    "#display(truthFinal_df[np.logical_and((truthFinal_df.NewDrug==0), (truthFinal_df.Trail_Drug_DBID.apply(len)!=0))].head(50))\n",
    "\n",
    "display(truthFinal_df[np.logical_and((truthFinal_df.NewDrug==0), (truthFinal_df.iDBIDCount!=0))].shape)\n",
    "display(truthFinal_df[np.logical_and((truthFinal_df.NewDrug==0), (truthFinal_df.iDBIDCount!=0))].head(50))\n",
    "\n",
    "display(truthFinal_df[np.logical_and((truthFinal_df.NewDrug==1), (truthFinal_df.iDBIDCount!=0))].shape)\n",
    "display(truthFinal_df[np.logical_and((truthFinal_df.NewDrug==1), (truthFinal_df.iDBIDCount!=0))].head(50))\n",
    "\n",
    "display(truthFinal_df[np.logical_and((truthFinal_df.NewDrug==1), (truthFinal_df.iDBIDCount==0))].shape)\n",
    "display(truthFinal_df[np.logical_and((truthFinal_df.NewDrug==1), (truthFinal_df.iDBIDCount==0))].head(200))\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "truthMatch_df = truthFinal_df[truthFinal_df.iDBIDCount!=0]\n",
    "#display(truthMatch_df.shape)\n",
    "#display(truthMatch_df.head(40))\n",
    "display(truthMatch_df['NewDrug'].value_counts())\n",
    "display(truthMatch_df['iDBIDCount'].value_counts())\n",
    "\n",
    "tmids = truthMatch_df.apply(lambda x: pd.Series(x['Trail_Drug_DBID']),axis=1).stack().reset_index(level=1, drop=True)\n",
    "tmids.name = 'iDBID'\n",
    "#display(tmids)\n",
    "\n",
    "truthMatch_df = truthMatch_df.drop(['Trail_Drug_DBID', 'iDBIDCount'], axis=1).join(tmids)\n",
    "display(truthMatch_df.shape)\n",
    "display(truthMatch_df[10:30])\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "truthMatch_df.drop_duplicates(subset='iDBID', keep='first', inplace=True)\n",
    "display(truthMatch_df.shape)\n",
    "display(truthMatch_df[10:30])\n",
    "display(truthMatch_df['NewDrug'].value_counts())\n"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# flag if DB ID has proteins associated or not\n",
    "display(dbProteins_df.shape)\n",
    "display(dbProteins_df.head())\n",
    "\n",
    "# count proteins per DBID\n",
    "proteinCount_df = pd.DataFrame(dbProteins_df.drugbank_id.value_counts().reset_index().values, columns=[\"iDBID\", \"ProteinCount\"])\n",
    "proteinCount_df.sort_values(by=['iDBID'], inplace=True)\n",
    "proteinCount_df.reset_index(drop=True, inplace=True)\n",
    "display(proteinCount_df.shape)\n",
    "display(proteinCount_df.head())\n",
    "\n",
    "display(truthMatch_df.shape)\n",
    "display(truthMatch_df.head())\n",
    "\n",
    "# merge count in\n",
    "truthMatch2_df = truthMatch_df.merge(proteinCount_df, how=\"left\", on='iDBID').fillna(0)\n",
    "display(truthMatch2_df.shape)\n",
    "display(truthMatch2_df.head())\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# merge fda truth in to validate new/old status\n",
    "\n",
    "# first dedupe old Truth_df\n",
    "display(Truth_df.shape)\n",
    "Truth_df.drop_duplicates(subset='drugbank_id', keep='first', inplace=True)\n",
    "display(Truth_df.shape)\n",
    "display(Truth_df[['drugbank_id', 'truth']].head())\n",
    "\n",
    "truthMatch2_df = truthMatch2_df.merge(Truth_df[['drugbank_id', 'truth']], how=\"left\", left_on='iDBID', right_on='drugbank_id').fillna(0)\n",
    "display(truthMatch2_df.shape)\n",
    "display(truthMatch2_df.head())\n",
    "\n",
    "display(pd.crosstab(truthMatch2_df.truth, truthMatch2_df.NewDrug, margins=True))\n",
    "\n",
    "# fix incorrect NewDrug flags\n",
    "truthMatch2_df.NewDrug[truthMatch2_df.truth==1] = 0\n",
    "display(pd.crosstab(truthMatch2_df.truth, truthMatch2_df.NewDrug, margins=True))\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "display(truthMatch2_df.shape)\n",
    "display(truthMatch2_df.head())\n",
    "display(pd.crosstab(truthMatch2_df.ProteinCount>0, truthMatch2_df.NewDrug, margins=True))\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# UniProt - protein IDs / synonyms  ( to merge in with STRING and Virus/Protein data so they can merge with DrugBank)\n",
    "\n",
    "# exclude UniProt IDs beginning with A0A per this reference:\n",
    "# https://ftp.uniprot.org/pub/databases/uniprot/knowledgebase/docs/sec%5Fac.txt\n",
    "\n",
    "with open(UniProtPath + 'HUMAN_9606_idmapping.dat') as f:\n",
    "    row_count = sum(1 for row in f)\n",
    "display(row_count)\n",
    "\n",
    "# can I read all of just column 1 ?\n",
    "# if yes - I can use that to create an array of only STRING, only Gene_Name and only GeneID \n",
    "#    and then just read columns 0 & 2 from THAT subset\n",
    "# else if that runs into space limits - just use GREP to extract the rows we want !\n",
    "#    grep Gene_Name *.dat\n",
    "altIDNames_df = pd.read_csv(UniProtPath + 'HUMAN_9606_idmapping.dat', usecols = [1], sep='\\t', header=None)\n",
    "altIDNames_df.columns = ['altIDName']\n",
    "display(altIDNames_df.shape)\n",
    "display(altIDNames_df.head())\n",
    "display(altIDNames_df.altIDName.value_counts())\n",
    "\n",
    "STRINGSkip = altIDNames_df.index[altIDNames_df.altIDName != 'STRING']\n",
    "EnsemblProSkip = altIDNames_df.index[altIDNames_df.altIDName != 'Ensembl_PRO']\n",
    "GNameSkip = altIDNames_df.index[altIDNames_df.altIDName != 'Gene_Name']\n",
    "GIDSkip = altIDNames_df.index[altIDNames_df.altIDName != 'GeneID']\n",
    "\n",
    "del altIDNames_df\n",
    "\n",
    "\n",
    "#-------------------\n",
    "# STRING ID matching\n",
    "display(STRINGSkip.shape)\n",
    "UniProtSTRINGIDs_df = pd.read_csv(UniProtPath + 'HUMAN_9606_idmapping.dat', usecols=[0,2], skiprows=set(STRINGSkip), sep='\\t', header=None)\n",
    "UniProtSTRINGIDs_df.columns = ['UniProtID', 'STRINGID']\n",
    "display(UniProtSTRINGIDs_df.shape)\n",
    "display(UniProtSTRINGIDs_df.head())\n",
    "\n",
    "#-------------------\n",
    "# Ensembl Pro matching\n",
    "display(EnsemblProSkip.shape)\n",
    "UniProtEnsemblePro_df = pd.read_csv(UniProtPath + 'HUMAN_9606_idmapping.dat', usecols=[0,2], skiprows=set(EnsemblProSkip), sep='\\t', header=None)\n",
    "UniProtEnsemblePro_df.columns = ['UniProtID', 'Ensembl_PRO']\n",
    "UniProtEnsemblePro_df['Ensembl_PRO9606'] = '9606.'+UniProtEnsemblePro_df['Ensembl_PRO']\n",
    "display(UniProtEnsemblePro_df.shape)\n",
    "display(UniProtEnsemblePro_df.head())\n",
    "\n",
    "#-------------------\n",
    "# Gene ID matching\n",
    "display(GIDSkip.shape)\n",
    "UniProtGeneIDs_df = pd.read_csv(UniProtPath + 'HUMAN_9606_idmapping.dat', usecols=[0,2], skiprows=set(GIDSkip), sep='\\t', header=None)\n",
    "UniProtGeneIDs_df.columns = ['UniProtID', 'GeneID']\n",
    "\n",
    "# strip out duplicate UniProt GeneID rows - or should we be setting an order preference\n",
    "UniProtGeneIDs_df['FirstChar'] = UniProtGeneIDs_df['UniProtID'].str.slice(0,1)\n",
    "UniProtGeneIDs_df['A0A_Type'] = (UniProtGeneIDs_df['UniProtID'].str.slice(0,3) == 'A0A')\n",
    "UniProtGeneIDs_df['ID_Length'] = UniProtGeneIDs_df['UniProtID'].str.len()\n",
    "cols = ['FirstChar', 'A0A_Type', 'ID_Length']\n",
    "display(UniProtGeneIDs_df.groupby(cols)[cols].count())\n",
    "\n",
    "#UniProtGeneIDs_df = UniProtGeneIDs_df[UniProtGeneIDs_df['ID_Length'] == 6]\n",
    "UniProtGeneIDs_df = UniProtGeneIDs_df[UniProtGeneIDs_df['A0A_Type'] == False]\n",
    "#UniProtGeneIDs_df = UniProtGeneIDs_df[UniProtGeneIDs_df['FirstChar'].isin(['O', 'P', 'Q'])]\n",
    "UniProtGeneIDs_df.drop(columns=['FirstChar', 'A0A_Type', 'ID_Length'], inplace=True)\n",
    "\n",
    "# if > 1 UniProt row for a Host_Gene_ID, then keep P, then Q, then first of any remaining UniProt row(s)\n",
    "GeneRows = UniProtGeneIDs_df.GeneID.value_counts()\n",
    "print('The gene IDs with the top 25 most protein counts: ', GeneRows[:25])\n",
    "\n",
    "display(UniProtGeneIDs_df.shape)\n",
    "display(UniProtGeneIDs_df.head())\n",
    "\n",
    "#-------------------\n",
    "# Gene Name matching\n",
    "display(GNameSkip.shape)\n",
    "UniProtGeneNames_df = pd.read_csv(UniProtPath + 'HUMAN_9606_idmapping.dat', usecols=[0,2], skiprows=set(GNameSkip), sep='\\t', header=None)\n",
    "UniProtGeneNames_df.columns = ['UniProtID', 'GeneName']\n",
    "display(UniProtGeneNames_df.shape)\n",
    "display(UniProtGeneNames_df.head())\n",
    "\n",
    "# will probably need to repeat gene-id cleansing steps above if using gene name to match\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# example of a gene with 29 proteins (4 of the A0A type)\n",
    "# https://worldwide.promega.com/FindMyGene/GeneDetail.aspx?ncbiid=7404\n",
    "display(UniProtGeneIDs_df[UniProtGeneIDs_df.GeneID == 7404])\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# VirusHost - virus / protein\n",
    "VirusHostProt_df = pd.read_csv(VHProtPath + 'HCoV-associated host proteins.csv')\n",
    "display(VirusHostProt_df.shape)\n",
    "display(VirusHostProt_df.head())\n",
    "\n",
    "# now get UniProtID merged in on Gene_ID (match on Host_Protein should be equivalent)\n",
    "#display(UniProtGeneIDs_df.head())\n",
    "\n",
    "VirusHostProt_df = pd.merge(VirusHostProt_df, UniProtGeneIDs_df, how=\"left\", left_on='Host_Gene_ID', right_on='GeneID', indicator=True)\n",
    "print(\"after match (expecting both=130, right/left only = 0): \")\n",
    "display(VirusHostProt_df['_merge'].value_counts())\n",
    "VirusHostProt_df.drop(columns=['_merge', 'GeneID'], inplace=True)\n",
    "display(VirusHostProt_df.shape)\n",
    "display(VirusHostProt_df.head())\n"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#display(VirusHostProt_df.iloc[[0,1,2,4,5]])\n",
    "display(VirusHostProt_df.iloc[:200])\n"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<b>Duplicates exist even after elminating A0A type matches</b><br>\n",
    "<br>\n",
    "one example is gene_id 2932 = P49841 and Q6FI27<br>\n",
    "<br>\n",
    "https://www.uniprot.org/uniprot/?query=yourlist:M202103028471C63D39733769F8E060B506551E12176354Y&sort=yourlist:M202103028471C63D39733769F8E060B506551E12176354Y&columns=yourlist(M202103028471C63D39733769F8E060B506551E12176354Y),id,entry%20name,reviewed,protein%20names,genes,organism,length\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# STRING - protein/protein\n",
    "\n",
    "# NOTE - each pair is in the file 2x so only UniProtID1 needs to be matched\n",
    "# Example below:\n",
    "#[sasdemo@sasserver STRING]$ grep ENSP00000000233 *.txt | grep -e ENSP00000272298\n",
    "#9606.ENSP00000000233 9606.ENSP00000272298 490\n",
    "#9606.ENSP00000272298 9606.ENSP00000000233 490\n",
    "\n",
    "stringPP_df = pd.read_csv(STRINGPath + '9606.protein.links.v11.0.txt', sep=' ')\n",
    "display(stringPP_df.shape)\n",
    "display(stringPP_df.head())\n",
    "\n",
    "# merge Protein 1 to STRING on UniProt .dat file\n",
    "stringPP_df = pd.merge(stringPP_df, UniProtSTRINGIDs_df, how=\"left\", left_on='protein1', right_on='STRINGID', indicator=True)\n",
    "#display(stringPP_df['_merge'].value_counts())\n",
    "stringPP_df.rename(columns = {'UniProtID':'UniProtID1', 'STRINGID':'STRINGID1'}, inplace = True)\n",
    "stringPP_df.drop(columns=['_merge'], inplace=True)\n",
    "\n",
    "# merge Protein 1 to Ensembl_PRO on UniProt .dat file\n",
    "stringPP_df = pd.merge(stringPP_df, UniProtEnsemblePro_df[['UniProtID', 'Ensembl_PRO9606']], how=\"left\", left_on='protein1', right_on='Ensembl_PRO9606', indicator=True)\n",
    "#display(stringPP_df['_merge'].value_counts())\n",
    "\n",
    "# coalesce Protein 1 STRING and Ensemble_PRO columns (use Ensembl_PRO if STRING is missing)\n",
    "stringPP_df['UniProtID1'] = stringPP_df['UniProtID1'].mask(pd.isnull, stringPP_df['UniProtID'])\n",
    "stringPP_df.rename(columns = {'Ensembl_PRO9606':'Ensembl_PRO96061'}, inplace = True)\n",
    "stringPP_df.drop(columns=['_merge', 'UniProtID'], inplace=True)\n",
    "\n",
    "# merge protein 2 to STRING on UniProt .dat file\n",
    "stringPP_df = pd.merge(stringPP_df, UniProtSTRINGIDs_df, how=\"left\", left_on='protein2', right_on='STRINGID', indicator=True)\n",
    "#display(stringPP_df['_merge'].value_counts())\n",
    "stringPP_df.rename(columns = {'UniProtID':'UniProtID2', 'STRINGID':'STRINGID2'}, inplace = True)\n",
    "stringPP_df.drop(columns=['_merge'], inplace=True)\n",
    "\n",
    "# merge Protein 2 to Ensembl_PRO on UniProt .dat file\n",
    "stringPP_df = pd.merge(stringPP_df, UniProtEnsemblePro_df[['UniProtID', 'Ensembl_PRO9606']], how=\"left\", left_on='protein2', right_on='Ensembl_PRO9606', indicator=True)\n",
    "\n",
    "# coalesce Protein 2 STRING and Ensemble_PRO columns (use Ensembl_PRO if STRING is missing)\n",
    "stringPP_df['UniProtID2'] = stringPP_df['UniProtID2'].mask(pd.isnull, stringPP_df['UniProtID'])\n",
    "stringPP_df.rename(columns = {'Ensembl_PRO9606':'Ensembl_PRO96062'}, inplace = True)\n",
    "stringPP_df.drop(columns=['_merge', 'UniProtID'], inplace=True)\n",
    "\n",
    "print()\n",
    "print('After matching to STRING and Ensembl_PRO in UniProt')\n",
    "display(stringPP_df.shape)\n",
    "print(\"Rows with no match for STRING: \", stringPP_df.STRINGID1.isnull().count())\n",
    "print(\"Rows with no match for Ensebml_PRO: \", stringPP_df.Ensembl_PRO96061.isnull().count())\n",
    "print(\"Rows with no match for either: \", stringPP_df.UniProtID1.isnull().count())\n",
    "#print(\"Rows with no match for either: \", stringPP_df.UniProtID1.isnull().value_counts())\n",
    "print(\"NOTE: next most likely reason for missing is depricated IDs.  see note in markup cell below\")\n",
    "print()\n",
    "display(stringPP_df.head())\n",
    "\n",
    "print()\n",
    "print('Sample of Null matches:')\n",
    "display(stringPP_df[stringPP_df.UniProtID1.isnull()].head())\n",
    "#display(stringPP_df[stringPP_df.UniProtID1.isnull()].groupby('protein1')['protein1'].count())\n",
    "print(\"unique IDs with no match: \", stringPP_df[stringPP_df.UniProtID1.isnull()].groupby('protein1')['protein1'].count().count())\n",
    "\n",
    "# reset dataframe to contain only relevant columns\n",
    "stringPP_df = stringPP_df[['protein1', 'UniProtID1', 'protein2', 'UniProtID2', 'combined_score']]"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<b>searching UniProt ID Mapping.dat file for unmatched STRING IDs(without 9606 prefix\n",
    "gives no STRING IDs, but Ensembl_PRO</b>\n",
    "\n",
    "[sasdemo@sasserver UniProt]$ ls -ltr<br>\n",
    "-rw-r--r-- 1 cas sas 159854967 Jan 26 14:20 HUMAN_9606_idmapping.dat<br>\n",
    "\n",
    "[sasdemo@sasserver UniProt]$ grep -e \"ENSP00000016946\" *.dat<br>\n",
    "Q99666-1        Ensembl_PRO     ENSP00000016946<br>\n",
    "\n",
    "[sasdemo@sasserver UniProt]$ grep -e \"ENSP00000244537\" *.dat<br>\n",
    "P62805  Ensembl_PRO     ENSP00000244537<br>\n",
    "\n",
    "[sasdemo@sasserver UniProt]$ grep -e \"ENSP00000244537\" *.dat<br>\n",
    "P62805  Ensembl_PRO     ENSP00000244537<br>\n",
    "\n",
    "<b>searching UniProt ID Mapping.dat for a matched STRINGID (without 9606 prefix)\n",
    "gives both</b>\n",
    "[sasdemo@sasserver UniProt]$ grep -e \"ENSP00000380178\" *.dat<br>\n",
    "P62253  STRING  9606.ENSP00000380178<br>\n",
    "P62253  Ensembl_PRO     ENSP00000380178<br>\n",
    "\n",
    "<b><i>conclusion --> strip out 9606. and try matching to enesmbl_pro.  if that does not work, match STRING first, then match missing to Ensembl_PRO</b></i>\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<b>ENSP #s that do not match either STRING or Ensembl_PRO may be depricated IDs such as this one:</b><br>\n",
    "9606.ENSP00000195455 --> ENST00000195455<br>\n",
    "9606.ENSP00000377806 --> ENST00000377806<br>\n",
    "<br>\n",
    "https://useast.ensembl.org/Homo_sapiens/Transcript/Idhistory/Protein?t=ENSP00000195455\n",
    "https://useast.ensembl.org/Homo_sapiens/Transcript/Idhistory/Protein?t=ENSP00000377806\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3) load base to CAS"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "if casenabled == True:\n",
    "    #s.fileinfo(caslib='public') # files have been saved to caslib table backing store\n",
    "    s.tableinfo(caslib='public') # tables are loaded in memory (and may not have been saved)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# NOTE: upload_file() can upload disk files into CAS without using local dataframe memory\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# UniProt - select rows for matching:\n",
    "\n",
    "if casenabled == True:\n",
    "    s.droptable(caslib='public', name='UniProtGeneIDs', quiet=True)\n",
    "    UniProtGeneIDs_ct = s.upload_file(data=UniProtGeneIDs_df, casout=dict(name='UniProtGeneIDs', caslib='public', replication=0, promote=True))\n",
    "    display(UniProtGeneIDs_ct.info())\n",
    "    display(UniProtGeneIDs_ct.head())\n",
    "\n",
    "    s.droptable(caslib='public', name='UniProtSTRINGIDs', quiet=True)\n",
    "    UniProtSTRINGIDs_ct = s.upload_file(data=UniProtSTRINGIDs_df, casout=dict(name='UniProtSTRINGIDs', caslib='public', replication=0, promote=True))\n",
    "    UniProtSTRINGIDs_ct.info()\n",
    "    display(UniProtSTRINGIDs_ct.head())\n",
    "\n",
    "\n",
    "    s.droptable(caslib='public', name='UniProtGeneNames', quiet=True)\n",
    "    UniProtGeneNames_ct = s.upload_file(data=UniProtGeneNames_df, casout=dict(name='UniProtGeneNames', caslib='public', replication=0, promote=True))\n",
    "    UniProtGeneNames_ct.info()\n",
    "    display(UniProtGeneNames_ct.head())\n",
    "\n",
    "UniProtGeneIDs_df.to_csv(CSVOut+\"/\"+\"UniProtGeneIDs.csv\")\n",
    "UniProtSTRINGIDs_df.to_csv(CSVOut+\"/\"+\"UniProtSTRINGIDs.csv\")\n",
    "UniProtGeneNames_df.to_csv(CSVOut+\"/\"+\"UniProtGeneNames.csv\")\n"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# ClinicalTrials Truth (could possibly benefit from more cleaning):\n",
    "Truth_df.to_csv(CSVOut+\"/\"+\"Truth.csv\")\n",
    "if casenabled == True:\n",
    "    s.droptable(caslib='public', name='Truth', quiet=True)\n",
    "    Truth_ct = s.upload_file(data=Truth_df, casout=dict(name='Truth', caslib='public', replication=0, promote=True, label=\"Clinical Trials Truth: NOTE needs to be refined\"))\n",
    "    Truth_ct.info()\n",
    "    display(Truth_ct.head())\n",
    "\n",
    "# truthMatch2_df has information on the \"new\" source (non FDA Clinical Trials)\n",
    "truthMatch2_df.to_csv(CSVOut+\"/\"+\"newTruth.csv\")\n",
    "if casenabled == True:\n",
    "    s.droptable(caslib='public', name='newTruth', quiet=True)\n",
    "    newTruth_ct = s.upload_file(data=truthMatch2_df, casout=dict(name='newTruth', caslib='public', replication=0, promote=True, label=\"Clinical Trials Truth: NOTE needs to be refined\"))\n",
    "    newTruth_ct.info()\n",
    "    display(newTruth_ct.head())\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# VirusHost Proteins\n",
    "if casenabled == True:\n",
    "    s.droptable(caslib='public', name='VirusHostProt', quiet=True)\n",
    "    VirusHostProt_ct = s.upload_file(data=VirusHostProt_df, casout=dict(name='VirusHostProt', caslib='public', replication=0, promote=True, label=\"Virus Host Protein Relationships NOTE: Many Proteins had 1+ UniProt IDs\"))\n",
    "    display(VirusHostProt_ct.info())\n",
    "    display(VirusHostProt_ct.head())\n",
    "\n",
    "VirusHostProt_df.to_csv(CSVOut+\"/\"+\"VirusHostProt.csv\")\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# STRING - protein protein data\n",
    "if casenabled == True:\n",
    "    s.droptable(caslib='public', name='stringPP', quiet=True)\n",
    "    stringPP_ct = s.upload_file(data=stringPP_df, casout=dict(name='stringPP', caslib='public', replication=0, promote=True, label=\"STRING Protein Protein interactions NOTE Missing UniProt Matches\"))\n",
    "    stringPP_ct.info()\n",
    "    display(stringPP_ct.head())\n",
    "\n",
    "stringPP_df.to_csv(CSVOut+\"/\"+\"stringPP.csv\")\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#NOTE: indication and description cause data errors when loading to a CASLIB - figure it out later\n",
    "\n",
    "display(dbSmallM_df[:5])\n",
    "\n",
    "# clean up drug bank small molecule list and merge in clinical trials \"truth\" flag\n",
    "x = dbSmallM_df[['drugbank_id', 'name', 'inchi', 'groups', 'atc_codes', 'categories']]\n",
    "\n",
    "# replace truth_df with truthMatch2_df\n",
    "#x = pd.merge(x, Truth_df[['drugbank_id', 'truth']], on='drugbank_id', how='left', indicator=True)\n",
    "newTruth = truthMatch2_df[['iDBID', 'NewDrug', 'ProteinCount']]\n",
    "newTruth['truth'] = 1\n",
    "display(newTruth.head()) \n",
    "\n",
    "x = pd.merge(x, newTruth, left_on='drugbank_id', right_on='iDBID', how='left', indicator=True)\n",
    "\n",
    "display(x['_merge'].value_counts())\n",
    "x.drop(columns=['_merge'], inplace=True)\n",
    "\n",
    "x.truth = x.truth.fillna(0)\n",
    "display(x['truth'].value_counts())\n",
    "\n",
    "\n",
    "# DrugBank Tables\n",
    "if casenabled == True:\n",
    "    s.droptable(caslib='public', name='dbSmallM_Truth', quiet=True)\n",
    "    #dbSmallM_ct = s.upload_file(data=dbSmallM_df, casout=dict(name='dbSmallM', caslib='public', replication=0, promote=True, label=\"Drug Bank: Small Molecule drugs (NOTE additional attributes available plus stings need to be parsed)\"))\n",
    "    dbSmallM_ct = s.upload_file(data=x, casout=dict(name='dbSmallM_Truth', caslib='public', replication=0, promote=True, label=\"Drug Bank: Small Molecule drugs (NOTE additional attributes available plus stings need to be parsed)\"))\n",
    "    dbSmallM_ct.info()\n",
    "    display(dbSmallM_ct.shape)\n",
    "    display(dbSmallM_ct.head())\n",
    "\n",
    "x.to_csv(CSVOut+\"/\"+\"dbSmallM_Truth.csv\")\n"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "# drug bank - drug/protein table(s)\n",
    "if casenabled == True:\n",
    "    s.droptable(caslib='public', name='dbProteins', quiet=True)\n",
    "    dbProteins_ct = s.upload_file(data=dbProteins_df, casout=dict(name='dbProteins', caslib='public', replication=0, promote=True, label=\"Drug Bank: Small Molcule related proteins (NOTE not all captured by XML parser yet)\"))\n",
    "    #dbProteins_ct = s.upload_file(data=dbProteins_df[:5], casout=dict(name='dbProteins', caslib='public', replication=0, promote=True, label=\"Drug Bank: Small Molcule related proteins\"))\n",
    "    dbProteins_ct.info()\n",
    "    display(dbProteins_ct.shape)\n",
    "    display(dbProteins_ct.head())\n",
    "\n",
    "dbProteins_df.to_csv(CSVOut+\"/\"+\"dbProteins.csv\")\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "3) Join tables and write result to CAS"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#s.close()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}